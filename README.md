# K-Fold-Cross-validation
This repository presents an in-depth implementation of four advanced cross-validation techniques in Python for robust model evaluation and validation:

# 1-Hold One Out Method: 
Also known as Leave-One-Out (LOO) cross-validation this technique assesses model performance by leaving one data point out for validation and training the model on the remaining data points iteratively.
# 2- K-Fold Method: 
the repository demonstrates partitioning the dataset into K equal subsets, training the model on K-1 folds, and validating on the remaining fold, repeating this process K times for comprehensive validation.
# 3-Stratified K-Fold Method: 
 Stratified K-Fold cross-validation ensures that each fold maintains the same class distribution as the original dataset, particularly useful for imbalanced datasets.
# 4-Leave One Out Method: 
 Similar to Hold One Out, this method systematically leaves one data point out for validation while training on the rest, effectively evaluating model performance across the entire dataset.
